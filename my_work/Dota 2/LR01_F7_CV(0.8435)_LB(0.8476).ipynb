{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from plotly import tools\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import eli5\n",
    "from sklearn import decomposition\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "import os\n",
    "from IPython.display import display_html\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle(\"./train_features_7.pkl\")\n",
    "X_test = pd.read_pickle(\"./test_features_7.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(data = X_train_scaled)\n",
    "X_test_df = pd.DataFrame(data = X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "      <th>384</th>\n",
       "      <th>385</th>\n",
       "      <th>386</th>\n",
       "      <th>387</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.291823</td>\n",
       "      <td>0.383071</td>\n",
       "      <td>0.683215</td>\n",
       "      <td>-0.851023</td>\n",
       "      <td>0.273937</td>\n",
       "      <td>-1.188395</td>\n",
       "      <td>-1.090415</td>\n",
       "      <td>-0.999064</td>\n",
       "      <td>-1.238755</td>\n",
       "      <td>-0.980373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>-0.01492</td>\n",
       "      <td>-0.002408</td>\n",
       "      <td>-0.001563</td>\n",
       "      <td>-0.005492</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>-0.002193</td>\n",
       "      <td>-0.003059</td>\n",
       "      <td>-0.007542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.636190</td>\n",
       "      <td>-2.471853</td>\n",
       "      <td>-1.463668</td>\n",
       "      <td>-0.542953</td>\n",
       "      <td>0.199121</td>\n",
       "      <td>0.031248</td>\n",
       "      <td>-0.942096</td>\n",
       "      <td>3.770391</td>\n",
       "      <td>0.144414</td>\n",
       "      <td>-0.925769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>-0.01492</td>\n",
       "      <td>-0.002408</td>\n",
       "      <td>-0.001563</td>\n",
       "      <td>-0.005492</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>-0.002193</td>\n",
       "      <td>-0.003059</td>\n",
       "      <td>-0.007542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.466485</td>\n",
       "      <td>0.541678</td>\n",
       "      <td>-1.463668</td>\n",
       "      <td>-1.005058</td>\n",
       "      <td>-0.549034</td>\n",
       "      <td>-1.188395</td>\n",
       "      <td>-1.164575</td>\n",
       "      <td>-0.999064</td>\n",
       "      <td>-1.238755</td>\n",
       "      <td>-1.223333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>-0.01492</td>\n",
       "      <td>-0.002408</td>\n",
       "      <td>-0.001563</td>\n",
       "      <td>-0.005492</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>-0.002193</td>\n",
       "      <td>-0.003059</td>\n",
       "      <td>-0.007542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 388 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -1.291823  0.383071  0.683215 -0.851023  0.273937 -1.188395 -1.090415   \n",
       "1 -0.636190 -2.471853 -1.463668 -0.542953  0.199121  0.031248 -0.942096   \n",
       "2 -1.466485  0.541678 -1.463668 -1.005058 -0.549034 -1.188395 -1.164575   \n",
       "\n",
       "        7         8         9    ...       378      379      380       381  \\\n",
       "0 -0.999064 -1.238755 -0.980373  ...  0.001402  0.00339 -0.01492 -0.002408   \n",
       "1  3.770391  0.144414 -0.925769  ...  0.001402  0.00339 -0.01492 -0.002408   \n",
       "2 -0.999064 -1.238755 -1.223333  ...  0.001402  0.00339 -0.01492 -0.002408   \n",
       "\n",
       "        382       383       384       385       386       387  \n",
       "0 -0.001563 -0.005492  0.000677 -0.002193 -0.003059 -0.007542  \n",
       "1 -0.001563 -0.005492  0.000677 -0.002193 -0.003059 -0.007542  \n",
       "2 -0.001563 -0.005492  0.000677 -0.002193 -0.003059 -0.007542  \n",
       "\n",
       "[3 rows x 388 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39675, 388)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 388)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=42, solver='liblinear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, X_test, y, params, folds, model_type='lgb', plot_feature_importance=False, averaging='usual', model=None):\n",
    "    oof = np.zeros(len(X))\n",
    "    prediction = np.zeros(len(X_test))\n",
    "    scores = []\n",
    "    feature_importance = pd.DataFrame()\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n",
    "        print('Fold', fold_n, 'started at', time.ctime())\n",
    "        X_train, X_valid = X.loc[train_index], X.loc[valid_index]\n",
    "        y_train, y_valid = y[train_index], y[valid_index]\n",
    "        \n",
    "        if model_type == 'lgb':\n",
    "            train_data = lgb.Dataset(X_train, label=y_train)\n",
    "            valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "            \n",
    "            model = lgb.train(params,\n",
    "                    train_data,\n",
    "                    num_boost_round=20000,\n",
    "                    valid_sets = [train_data, valid_data],\n",
    "                    verbose_eval=1000,\n",
    "                    early_stopping_rounds = 200)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "            \n",
    "        if model_type == 'xgb':\n",
    "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X_train.columns)\n",
    "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X_train.columns)\n",
    "\n",
    "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "            model = xgb.train(dtrain=train_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=500, params=params)\n",
    "            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X_train.columns), ntree_limit=model.best_ntree_limit)\n",
    "            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X_train.columns), ntree_limit=model.best_ntree_limit)\n",
    "        \n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_valid = model.predict_proba(X_valid).reshape(-1,)\n",
    "            score = roc_auc_score(y_valid, y_pred_valid)\n",
    "            print(f'Fold {fold_n}. AUC: {score:.4f}.')\n",
    "            print('')\n",
    "            \n",
    "            y_pred = model.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "        if model_type == 'glm':\n",
    "            model = sm.GLM(y_train, X_train, family=sm.families.Binomial())\n",
    "            model_results = model.fit()\n",
    "            model_results.predict(X_test)\n",
    "            y_pred_valid = model_results.predict(X_valid).reshape(-1,)\n",
    "            score = roc_auc_score(y_valid, y_pred_valid)\n",
    "            \n",
    "            y_pred = model_results.predict(X_test)\n",
    "            \n",
    "        if model_type == 'cat':\n",
    "            model = CatBoostClassifier(iterations=20000, learning_rate=0.05, loss_function='Logloss',  eval_metric='AUC', **params)\n",
    "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n",
    "\n",
    "            y_pred_valid = model.predict_proba(X_valid)[:, 1]\n",
    "            y_pred = model.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "        oof[valid_index] = y_pred_valid.reshape(-1,)\n",
    "        scores.append(roc_auc_score(y_valid, y_pred_valid))\n",
    "\n",
    "        if averaging == 'usual':\n",
    "            prediction += y_pred\n",
    "        elif averaging == 'rank':\n",
    "            prediction += pd.Series(y_pred).rank().values  \n",
    "        \n",
    "        if model_type == 'lgb':\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = X.columns\n",
    "            fold_importance[\"importance\"] = model.feature_importance()\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    prediction /= n_fold\n",
    "    \n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        feature_importance[\"importance\"] /= n_fold\n",
    "        if plot_feature_importance:\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12));\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "            plt.title('LGB Features (avg over folds)');\n",
    "        \n",
    "            return oof, prediction, feature_importance\n",
    "        return oof, prediction, scores\n",
    "    \n",
    "    else:\n",
    "        return oof, prediction, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "\n",
    "params = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = '../../data/dota_2/'\n",
    "\n",
    "df_train_targets = pd.read_csv(os.path.join(PATH_TO_DATA, \n",
    "                                            'train_targets.csv'), \n",
    "                                   index_col='match_id_hash')\n",
    "\n",
    "y = df_train_targets['radiant_win'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit, KFold\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores_extended = cross_val_score(model, X_train_scaled, y, \n",
    "                                     cv=cv, scoring='roc_auc', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extended features: mean=0.8428043499914086 scores=[0.84120501 0.84489773 0.84182356 0.84318956 0.84290589]\n"
     ]
    }
   ],
   "source": [
    "print('Extended features: mean={} scores={}'.format(cv_scores_extended.mean(), \n",
    "                                                    cv_scores_extended))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_features = pd.read_csv(os.path.join(PATH_TO_DATA, \n",
    "                                             'test_features.csv'), \n",
    "                                    index_col='match_id_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_scaled, y)\n",
    "df_submission = pd.DataFrame(\n",
    "    {'radiant_win_prob': model.predict_proba(X_test_scaled)[:, 1]}, \n",
    "    index=df_test_features.index,)\n",
    "\n",
    "df_submission.to_csv('submission_lr0_f7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_cv(X_heroes_train, y_train, cv=5, random_state=SEED):\n",
    "    logit = LogisticRegression(random_state=SEED, solver='liblinear')\n",
    "\n",
    "    c_values = np.logspace(-2, 1, 20)\n",
    "\n",
    "    logit_grid_searcher = GridSearchCV(estimator=logit, param_grid={'C': c_values},\n",
    "                                       scoring='roc_auc',return_train_score=False, cv=cv,\n",
    "                                       n_jobs=-1, verbose=0)\n",
    "\n",
    "    logit_grid_searcher.fit(X_heroes_train, y_train)\n",
    "    \n",
    "    cv_scores = []\n",
    "    for i in range(logit_grid_searcher.n_splits_):\n",
    "        cv_scores.append(logit_grid_searcher.cv_results_[f'split{i}_test_score'][logit_grid_searcher.best_index_])\n",
    "    print(f'CV scores: {cv_scores}')\n",
    "    print(f'Mean: {np.mean(cv_scores)}, std: {np.std(cv_scores)}\\n')\n",
    "    \n",
    "    return logit_grid_searcher.best_estimator_, np.array(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores: [0.846664484885221, 0.8342081447963801, 0.8470962708690903, 0.8481021267923615, 0.8414891560232478]\n",
      "Mean: 0.8435120366732601, std: 0.005186676045059978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit_1, cv_scores_1 = logit_cv(X_train_scaled, y, cv=folds, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_1.fit(X_train_scaled, y)\n",
    "df_submission = pd.DataFrame(\n",
    "    {'radiant_win_prob': logit_1.predict_proba(X_test_scaled)[:, 1]}, \n",
    "    index=df_test_features.index,)\n",
    "\n",
    "df_submission.to_csv('submission_lr1_f7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('X_train_for_cat.csv')\n",
    "X_test.to_csv('X_test_for_cat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
